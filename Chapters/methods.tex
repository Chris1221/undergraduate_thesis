\chapter{Methods}
\label{methods}


\section{Study Population}

There are four major cohorts used as a ``test''	 set in this study, comprising a total $n = 13371$.

\textbf{Ottawa Heart Genomics Study (OHGS):} Details of this cohort have been previously described \citep{Davies2012}. Both cases (1) and controls (0) were recruited from the Lipid Clinic at the University of Ottawa Heart Institute (UOHI). Cases with diabetes melliitus were entirely excluded. Cases were required to have at
least one of: a stenosis in a major epicardial vessel of at least 50\%; have had a percuteneous intervention (PCI); have had coronary artery bypass surgery (CABG); or have had a myocardial
infarction (MI). Earlier studies using this cohort examined the effect of age, and cases were required to be $\leq$ 55 years old for men and $\leq$ 65 years old for women. The controls were either healthy elderly patients recruited from the catherization laboratory or the UOHI; they had no stenosis $\geq 50\%$ in any major epicardial vessel and were required to be at minimum 65 years old for men and 70 years old for women. The study protocol was approved by the Human Research Ethics Board of the University of Ottawa Heart Institute and all participants provided informed consent.

\textbf{Cleveland Clinic (CCGB):} Cases and controls from the Cleveland Clinic Cohort followed the same collection procedure as outlined for OHGS except were collected at the catherization laboratory of the Cleveland Clinic.  


\textbf{Duke Cathgen Study (DUKE):} Both cases and controls were recruited from the catherization laboratory at Duke University. Cases were required to have at least one epicardial coronary vessel with $\geq$ 50\% stenosis while being at most 55 years old for males and 65 years old for females. Controls were asymptomatic and required to have $\leq 30$ \% stenosis in all coronary vessels. Subjects with diabetes melliitus, severe pulmonary hypertension or congenital heart disease were excluded. The study protocol was approved by the ethics committee and all participants provided informed consent.

\textbf{INTERHEART Cohort (ITH):} INTERHEART is a standardized case-control study of acute myocardial infarction from across the world. Only Caucasian participants were analyzed in this study due to issues with differing gene frequencies among ethnicities. Cases -- those showing acute MI, were age matched to within 5 years of controls who were community based individuals with no previous history or diagnosis of heart disease and exertional chest pain. The study protocol was approved by the ethics committees in all participating centers and all participants provided informed consent. A full list of ITH investigators is found at http://www.phri.ca/interheart/index2.html.

\section{Genotyping and Imputation}

SNP genotyping of the above cohorts was performed on either Affymetrix 6.0 or 500K chip arrays at the University of Ottawa Heart Institute using the recommended procedure from the manufacturer. They were processed as in \cite{Dandona2010,Schunkert2011}. Imputation was performed using IMPUTE2 and the August 2009 1000 Genomes reference panel. \citep{10.1371/journal.pgen.1000529}. Approximately 5.5 million \ac{SNP} passed quality control measures including info $> 0.5$, Hardy Weinburg Equilibrium $> 1 \times 10^{-6}$ and missingness $< 10\%$. 


\section{Training Populations}
\label{training}

This study additionally comprised two ``training'' populations which were used to estimate the $\hat{\beta}$ effects necessary for the construction of \ac{PRS}.

\textbf{GIANT Consortium: } \ac{GIANT} consortium attempts to identify genetic loci which may modulate human body size, height, and obesity. We use for this study their data on BMI predicting \ac{SNP} calculated from approximately $n = 123,865$ on close to 2M \acp{SNP}. Collection methodologies and specific information is outlined in \cite{Speliotes2010}.

\textbf{Global Lipids Consortium:} The Global Lipids Consortium estimates genetic effects in $n = 188,577$ individuals using whole genome and custom genotyping arrays. We use their estimated additive genetic effects for SNPs predicting \ac{TG}, \ac{HDLc}, and \ac{LDLc}. Collection methodologies and further information are outlined in \citep{Consortium2013}.

\textbf{CARDIoGRAMplusC4D:} The Coronary ARtery DIsease Genome wide Replication and Meta-analysis (CARDIoGRAM) plus The Coronary Artery Disease (C4D) Genetics is a collaborative effort combining \ac{GWAS} data from multiple data sources to better estimate potential genetic effects in \ac{CAD}. Their data represents 22 studies with 22,233 cases and 64,762 controls of European individuals. Further information and collection methodology is outlined in \cite{TheCARDIoGRAMplusC4DConsortium2015}.


\section{Polygenic Prediction of CAD}

In the following analysis we primarily compare three different methods for constructing \ac{PRS} $\hat{S}$.

\subsection{Traditional Risk Score}

The first, which we denote as the ``traditional risk score'', or $\hat{S}_{TRS}$. This score uses the ``traditional'' approach of only using the highest confidence genome wide significant loci for \ac{CAD} in the construction of the score. We derive the estimated $\underline{\hat{\beta}}$ effects from \citep{TheCARDIoGRAMplusC4DConsortium2015}, whose methodology is described above. We only use the 212 variants from this section which have been shown to be FDR signficicant with $q < 0.05$ across the whole genome, as is common practice. Recall from the derivation leading up to equation \ref{score} that \ac{PRS} $S$ for individual $n$ is described as  $$ S = \sum^m_{i=1} \beta_i G_{ni} $$ Therefore for this score, we define $\hat{\beta}$ as a vector of length 212 with each of the estimated additive genetic effects derived from CARDIoGRAM plus C4D, and construct estimated score $\hat{S}$ for individual $n$ as $$ \hat{S}_{n, TRS} \equiv \sum^{212}_{i = 1} \hat{\beta}_i \mathbf{G}_{n, i} $$ This forms the basis for our first model.

\subsection{Cardiometabolic Risk Score}
\label{cmb-rs}

The second score which we estimate is a novel derivation. We aim to use genetic information from several co-morbid conditions together to better explain \ac{CAD}. The motivation is that important signals may be spuriously insignificant in large meta analyses, or simply have too low effect to be accurately categorized as significant; taking information from co-morbid conditions allows researchers a wider span of information to integrate. 

We use meta data from four co-morbid conditions to estimate the genetic effects of these traits and \textbf{re-prioritize} variants with the intention of creating a minimal score for \ac{CAD} which better predicts the phenotype. 

First, we introduce some new notation. We denote $\underline{\hat{\beta}}_{LDLc}, \underline{\hat{\beta}}_{HDLc}, \underline{\hat{\beta}}_{TG}, \underline{\hat{\beta}}_{BMI}$ as the vectors of estimated effects for \ac{LDLc}, \ac{HDLc}, \ac{TG}, and \ac{BMI} respectively derived from the training sets outlined in section \ref{training}.

We separately order variants by their P value and say $m^*$ is the number of genome-significant significant ($q \leq 0.05$) hits found in each study. We take $1 \dots m^*$ from each data set and call this set of variants $\underline{G}^*$ for important genetic effects. We define the set $G^*$ as containing all genetic elements $\mathbf{G}_i$ such that $i$ is a part of our selected significant ordered set $1 \dots m^* $.

$$ \begin{aligned} G^* &\equiv \{ \mathbf{G}_i | i \in 1 \dots m^* \} &&&&&& m^* \, |  \, q < 0.05 \end{aligned}$$


We then take all genetic effects $i \in G^*$ and calculate a score based on these variants instead of the 212. We define this new \ac{CMB} score for any individual $n$ as $\hat{S}_{CMB}$:

$$ \hat{S}_{CMB} \equiv \sum_{i \in G^*_{LDLc}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{HDLc}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{TG}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{TG}} \hat{\beta}_i \mathbf{G}_{n, i} $$

We use this new score to predict \ac{CAD}, with the hypothesis that incorporating several co-morbid conditions will better prioritize variants in order to achieve increased predictive accuracy. 

\subsection{Optimal Cardiometabolic Risk Score}

We further extend this $\hat{S}_{CMB}$ using \ac{oPRS} as introduced in section \ref{oPRS}. Instead of selecting $m^*$ to be all variants such that $q < 0.05$, we select all P values such that $P < T_{o}$ where $T_{o}$ is the optimal threshold found by iterating through $P$ value thresholds for score inclusion.

$$ \begin{aligned} G^* &\equiv \{ \mathbf{G}_i | i \in 1 \dots m^* \} &&&&&& m^* \, |  \, P < T_{o} \end{aligned}$$

And similarly construct our optimal cardiometabolic risk score as before:


$$ \hat{S}_{oCMB} \equiv \sum_{i \in G^*_{LDLc}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{HDLc}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{TG}} \hat{\beta}_i \mathbf{G}_{n, i} + \sum_{i \in G^*_{TG}} \hat{\beta}_i \mathbf{G}_{n, i} $$

This forms the new optimal score for testing.

\section{Statistical Analysis}

\subsection{Construction of \ac{PRS}}

\ac{PRS} were constructed in both R and Plink v1.90 (https://www.cog-genomics.org/plink2) with validation in Plink v 1.07 (http://pngu.mgh.harvard.edu/~purcell/plink/). Each of approximately 5.5M imputed, post quality control, \ac{GWAS} were coded as 0,1, or 2, depending on the number of minor alleles present. \ac{PRS} was calculated as described in previous sections and a normal distribution was validated using both empirical tests (Levene, Shapiro-Wilk) and qualitative observations on qq plots and histograms. Each \ac{PRS} was confirmed to have a normal distribution, validating one of the assumptions of future models. 

Optimal \ac{PRS} (\ac{oPRS}) were constructed again using R and Plink 1.90/1.07, though with the assistance of PRSice. \citep{Euesden2014} To determine optimal thresholds for \ac{SNP} inclusion, \acp{SNP} were ordered by $P$ value and 2500 ``slices'' or thresholds were created between $P = 0.0001$ and $P = 0.25$. For each of these thresholds, a logistic regression model was created, as detailed below, and the $P$ value of association was calculated. The model was adjusted for the first two principal components and sex. The maximal $P$ value of association was observed and extracted. Based on permutation analysis in the original publication, since our \ac{oPRS} showed $P$-values of association less than $\alpha = 0.001$, our association was deemed to be significant overcoming multiple testing correction. Results were graphically displayed using both base plotting in R and ggplot2. 

\subsection{Predictive Model}

In order to predict \ac{CAD} with our \ac{PRS}, covariate adjusted logistic (binomial) regression models were used. Scores were always adjusted for the first two principal components to adjust for population stratification. Nagelkerke's Pseudo $R^2$, gives an estimation of the scaled explained variance of a logistic model. It is given by

$$ R^2 = 1 - \left\{  \frac{L(M_{intercept})}{L(M_{full})}  \right\}^{\frac{2}{N}} $$

Where $L(M)$ is the conditional probability of the outcome variable (\ac{CAD}) given the independent variables and $L$ is the likelihood function operator. A full description of the operator is given in \cite{Nagelkerke1991}.

Area under the receiver operator character curve, also known as the $c$-statistic, is a well known proxy for predictive accuracy of a binary model. It was calculated in the pROC package in R (\cite{Robin2011}). Differences between ROC model was assessed firstly by the method for correlated ROC curves proposed by \cite{DeLong1988}. A secondary, more robust, difference was estimated through 1000 bootstrap permutations of dependent variables in R. 

Meta analysis was conducted in the metafor package in R. \citep{metafor} Random effects were assumed for study variables to have greater applicable to the population at large. 

\section{Computational Resources}

All analyses were performed at the Center for Advanced Computing, a large scale Red Hat Enterprise linux parallel computing cluster used to quickly analyze large sets of data. All analysis was parallelized either using inbuilt libraries or OpenMPI standards. 

Analyses were performed in R version 3.2.3 (https://www.r-project.org/), Python legacy version 2.7.9 (https://www.python.org/), Plink (http://pngu.mgh.harvard.edu/~purcell/plink/), and GCTA (http://cnsgenomics.com/software/gcta/).

All analysis was logged and stored securely and anonymously; back ups of all data were made and encrypted.

All analysis was version controlled using git + github and this thesis is entirely reproducible. Any code available upon request. 

\let\cleardoublepage\clearpage